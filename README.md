# ğŸ§  Zava Travel Inc. â€” Multi-Agent Social Media Content Creator

**Track**: Reasoning Agents with Microsoft Foundry | **Hackathon**: Agents League @ TechConnect

> Three AI agents collaborate in a group chat to generate, review, and publish platform-ready social media content for Zava Travel Inc.

---

## ğŸ—ï¸ Architecture

```
Campaign Brief (User Input)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         GROUP CHAT ORCHESTRATOR                  â”‚
â”‚         (Round-Robin Speaker Selection)          â”‚
â”‚                                                  â”‚
â”‚   Creator â†’ Reviewer â†’ Creator â†’ Reviewer â†’ Publisher
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚              â”‚
     â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CREATOR  â”‚ â”‚ REVIEWER â”‚ â”‚PUBLISHER â”‚
â”‚(Azure AI)â”‚ â”‚(Copilot) â”‚ â”‚(Azure AI)â”‚
â”‚          â”‚ â”‚          â”‚ â”‚          â”‚
â”‚ Chain-of â”‚ â”‚  ReAct   â”‚ â”‚  Self-   â”‚
â”‚ Thought  â”‚ â”‚ Pattern  â”‚ â”‚Reflectionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    3 Platform-Ready Posts
                  (LinkedIn, Twitter, Instagram)
```

### System Architecture

![System Architecture](docs/images/architecture.svg)

### Data Flow (Content Generation)

![Data Flow](docs/images/dataflow.svg)

| Component       | Engine                  | Reasoning Pattern                       | Role                                                     |
| --------------- | ----------------------- | --------------------------------------- | -------------------------------------------------------- |
| **Orchestrator** | Agent Framework GroupChat | Router (inspect state â†’ decide â†’ dispatch) | Routes conversation flow with intelligent fast-tracking |
| **Creator**     | Azure OpenAI (GPT-5.x) | Chain-of-Thought (5 steps)              | Drafts content with visible reasoning                    |
| **Reviewer**    | GitHub Copilot SDK      | ReAct (Observe â†’ Think â†’ Act â†’ Result)  | Reviews brand alignment & quality                        |
| **Publisher**   | Azure OpenAI (GPT-5.x) | Self-Reflection (validate constraints)  | Formats for LinkedIn, Twitter, Instagram                 |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Node.js 18+ and npm (for MCP filesystem server + frontend)
- Azure Subscription with AI Foundry project & deployed reasoning model
- Azure CLI (`az login`)
- GitHub Copilot CLI (authenticated with `/login`)

### Setup

```powershell
# 1. Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1

# 2. Install Python dependencies
pip install --pre -r requirements.txt

# 3. Install MCP filesystem server
npm install -g @modelcontextprotocol/server-filesystem
# Optional: only needed if using MCP_TRANSPORT=streamable-http
# npm install -g supergateway

# 4. Install frontend dependencies
cd frontend
npm install
cd ..

# 5. Configure environment
copy .env.sample .env
# Edit .env with your Azure endpoints

# 6. Authenticate
az login
```

### Running the Application

You can run the workflow in two ways:

#### Option A: Full Stack (frontend + API server)

Open **two terminals**:

**Terminal 1 â€” Backend API server** (port 8000):

```powershell
.\venv\Scripts\Activate.ps1
python api_server.py
# API available at http://localhost:8000
# Health check: GET http://localhost:8000/api/health
```

**Terminal 2 â€” Frontend dev server** (port 5173):

```powershell
cd frontend
npm run dev
# Open http://localhost:5173 in your browser
```

Then open http://localhost:5173, log in with a demo account, and click **Generate Content**.

#### Option B: CLI Only (no frontend)

```powershell
python workflow_social_media.py
```

Output is printed to the console and saved to `./output/social-posts-*.md`.

#### Demo Accounts

| Username           | Password     | Role                 |
| ------------------ | ------------ | -------------------- |
| `sarah.explorer`   | `zava2026`   | Content Lead         |
| `marco.adventures` | `wander2026` | Social Media Manager |
| `admin`            | `admin`      | Administrator        |

### API Endpoints

| Method | Path            | Description                                  |
| ------ | --------------- | -------------------------------------------- |
| `GET`  | `/api/health`   | Health check â€” returns `{"status": "ok"}`    |
| `POST` | `/api/generate` | Run multi-agent workflow with campaign brief |

**POST `/api/generate`** request body:

```json
{
  "brand_name": "Zava Travel Inc.",
  "industry": "Travel â€” Budget-Friendly Adventure",
  "target_audience": "Millennials & Gen-Z adventure seekers",
  "key_message": "Wander More, Spend Less â€” affordable curated itineraries starting at $699",
  "destinations": "Bali, Patagonia, Iceland, Vietnam, Costa Rica",
  "platforms": ["LinkedIn", "Twitter", "Instagram"]
}
```

**Response** (JSON):

```json
{
  "status": "success",
  "posts": { "linkedin": "...", "twitter": "...", "instagram": "..." },
  "transcript": [
    {
      "agent_name": "Creator",
      "content": "...",
      "reasoning_pattern": "Chain-of-Thought",
      "timestamp": "..."
    }
  ],
  "duration_seconds": 42.5,
  "termination_reason": "Reviewer approved â€” fast-tracked to Publisher"
}
```

### Environment Variables (`.env`)

```env
AZURE_AI_FOUNDRY_PROJECT_ENDPOINT=https://<resource>.services.ai.azure.com/api/projects/<project>
AZURE_OPENAI_ENDPOINT=https://<resource>.services.ai.azure.com
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=<your-deployed-model>
MCP_TRANSPORT=stdio                    # Optional â€” 'stdio' (default) or 'streamable-http'
MCP_SERVER_PORT=8001                   # Optional â€” supergateway port (only for streamable-http)
```

---

## ğŸ§ª Running Automated Tests

The project includes comprehensive Playwright automated tests for the frontend application. All 84 functional test cases have been implemented covering login, dashboard, campaign creation, and content generation workflows.

### Prerequisites

- **Node.js 18+** installed
- **Chrome browser** installed (required by Playwright)
- Frontend application configured with `WEBSITE_ENTRY_POINT` in `.env`

### Setup & Run Tests

```powershell
# Navigate to test directory
cd FunctionalTestCases

# Install dependencies (first time only)
npm install

# Install Playwright browsers (first time only)
npx playwright install chromium

# Run all tests
npm test

# Run specific test suite
npm run test:us001  # Login tests (15 tests)
npm run test:us002  # Dashboard tests
# ... etc

# Run tests with visible browser (headed mode)
npm test -- --headed

# Run tests in UI mode (interactive debugging)
npm run test:ui

# View HTML report
npm run report
```

### Test Coverage

- âœ… **15 Login tests** - Authentication, demo accounts, form validation
- âœ… **6 Dashboard tests** - Hero section, statistics, agent team display
- âœ… **12 Campaign Brief tests** - Form display, editing, submission
- âœ… **5 Agent Collaboration tests** - Loading states, progress tracking
- âœ… **7 Generated Posts tests** - Content display, character counts
- âœ… **8 Copy to Clipboard tests** - All platforms, content preservation
- âœ… **7 Agent Transcript tests** - Message display, formatting
- âœ… **9 Navigation tests** - Sidebar, routing, active states
- âœ… **8 Logout tests** - Session management, security
- âœ… **7 Empty State tests** - Initial state, transitions

**Total**: 84 automated functional tests

For detailed test documentation, see [FunctionalTestCases/README.md](FunctionalTestCases/README.md)

---

## ğŸ“‹ Demo Campaign

The default campaign showcases Zava Travel's **"Wander More, Spend Less"** summer adventure:

| Attribute        | Value                                                     |
| ---------------- | --------------------------------------------------------- |
| **Company**      | Zava Travel Inc. (zavatravel.com)                         |
| **Industry**     | Budget-friendly adventure travel                          |
| **Audience**     | Millennials & Gen-Z adventure seekers                     |
| **Tone**         | Adventurous & Inspiring                                   |
| **Destinations** | Bali, Patagonia, Iceland, Vietnam, Costa Rica             |
| **Hashtags**     | #ZavaTravel #WanderMore #AdventureAwaits #TravelOnABudget |

### Example Output

The system produces three platform-ready posts:

- **LinkedIn**: Professional-adventurous, 1-3 paragraphs, 3-5 hashtags
- **X/Twitter**: Under 280 characters, punchy, 2-3 hashtags
- **Instagram**: Visual-friendly, emojis, 5-10 hashtags, image suggestions

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ api_server.py                   # FastAPI backend (POST /api/generate)
â”œâ”€â”€ workflow_social_media.py        # CLI entry point
â”œâ”€â”€ frontend/                       # React + Vite + Fluent UI frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/CreateContentPage.tsx   # Campaign brief form + results display
â”‚   â”‚   â”œâ”€â”€ pages/DashboardPage.tsx       # Dashboard with agent info
â”‚   â”‚   â”œâ”€â”€ services/api.ts              # API client (calls /api/generate)
â”‚   â”‚   â””â”€â”€ context/AuthContext.tsx       # Demo authentication
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ creator.py                  # Chain-of-Thought agent instructions
â”‚   â”œâ”€â”€ reviewer.py                 # ReAct agent instructions
â”‚   â””â”€â”€ publisher.py                # Self-Reflection agent instructions
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ speaker_selection.py        # Round-robin + fast-track logic
â”‚   â””â”€â”€ termination.py              # 3 termination conditions
â”œâ”€â”€ grounding/
â”‚   â”œâ”€â”€ file_search.py              # Brand guidelines grounding (embedded in instructions)
â”‚   â””â”€â”€ brand-guidelines.md         # Zava Travel brand guidelines
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ tracing.py                  # OpenTelemetry + Azure Monitor setup
â”‚   â”œâ”€â”€ pii_middleware.py           # PII scrubbing SpanProcessor
â”‚   â””â”€â”€ agent_middleware.py         # Per-agent telemetry child spans
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ agent_runner.py             # Runs workflow for each test brief
â”‚   â”œâ”€â”€ evaluate.py                 # 5 evaluators + report generation
â”‚   â””â”€â”€ eval_dataset.jsonl          # 3 campaign brief test cases
â”œâ”€â”€ safety/
â”‚   â”œâ”€â”€ content_shield.py           # Two-layer shield (Azure CS + brand filters)
â”‚   â””â”€â”€ brand_filters.py            # Local regex filters (competitors, banned words, PII, jailbreak)
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ filesystem_mcp.py           # MCP filesystem (stdio + optional HTTP Streamable)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ formatting.py               # Platform validation
â”‚   â”œâ”€â”€ transcript_formatter.py     # Conversation display
â”‚   â””â”€â”€ markdown_formatter.py       # Export to markdown
â”œâ”€â”€ config/
â”‚   â””â”€â”€ env_loader.py               # Environment validation
â”œâ”€â”€ test-data/                      # Synthetic test data
â”‚   â”œâ”€â”€ campaign-briefs/            # 5 campaign brief inputs
â”‚   â”œâ”€â”€ expected-outputs/           # Golden reference posts
â”‚   â”œâ”€â”€ grounding/                  # Brand guidelines document
â”‚   â”œâ”€â”€ safety-tests/               # 16 content safety test cases
â”‚   â”œâ”€â”€ evaluation-baselines/       # Quality score thresholds
â”‚   â””â”€â”€ edge-cases/                 # 8 edge case inputs
â”œâ”€â”€ output/                         # Generated posts saved here
â”œâ”€â”€ .env.sample                     # Environment template
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ constitution.md                 # Project governing principles
```

---

## ğŸ§  Reasoning Patterns

### Creator â€” Chain-of-Thought

```
Step 1: Identify the campaign objective
Step 2: Consider audience interests and pain points
Step 3: Draft an attention-grabbing hook
Step 4: Build the body with value and destination highlights
Step 5: Close with a clear call-to-action
```

### Reviewer â€” ReAct

```
Observation: The draft uses "cheap travel" language
Thought:    Zava's brand voice is "adventurous & inspiring" â€” should feel empowering
Action:     Recommend replacing "cheap" with "budget-savvy adventure"
Result:     Revised draft maintains aspirational tone while communicating value
```

### Publisher â€” Self-Reflection

```
Draft:  [formatted LinkedIn post]
Check:  Professional-adventurous tone? âœ“
Check:  3-5 hashtags including #ZavaTravel? âœ“
Check:  CTA with zavatravel.com? âœ“
Final:  [polished post ready for publication]
```

---

## ï¿½ Agentic Evaluation

The project includes a full evaluation pipeline using the **Azure AI Evaluation SDK** to measure content quality across multiple dimensions.

### Evaluators

| #   | Evaluator                  | Type       | What It Measures                                                  | Scale          |
| --- | -------------------------- | ---------- | ----------------------------------------------------------------- | -------------- |
| 1   | **TaskAdherenceEvaluator** | Built-in   | Did agents follow their instructions and produce expected output? | Binary (Pass/Fail) |
| 2   | **CoherenceEvaluator**     | Built-in   | Is the output natural, well-written, and logically structured?    | 1â€“5            |
| 3   | **RelevanceEvaluator**     | Built-in   | Does the output address the campaign brief?                       | 1â€“5            |
| 4   | **GroundednessEvaluator**  | Built-in   | Is content grounded in the brand guidelines?                      | 1â€“5            |
| 5   | **PlatformComplianceEvaluator** | Custom code | Twitter â‰¤280 chars, Instagram has emojis/hashtags, no banned words | 1â€“5        |

### Test Dataset

Three campaign briefs in `evaluation/eval_dataset.jsonl`:

| ID     | Brief                                           |
| ------ | ----------------------------------------------- |
| CB-001 | Summer Adventure Campaign (5 destinations)      |
| CB-002 | Vietnam Itinerary Launch (Hanoi â†’ HCMC)         |
| CB-003 | 48-Hour Flash Sale on Bali (30% off)            |

### Running Evaluation

```powershell
# Step 1 â€” Generate agent responses for each test brief
$env:PYTHONIOENCODING="utf-8"
.\venv\Scripts\python.exe evaluation/agent_runner.py

# Step 2 â€” Run evaluators and produce report
.\venv\Scripts\python.exe evaluation/evaluate.py
```

Results are saved to `evaluation/eval_report.json` with per-row scores and aggregate metrics.

### Latest Results

| Evaluator            | Score          |
| -------------------- | -------------- |
| Task Adherence       | PASS âœ…        |
| Coherence            | 4.67 / 5       |
| Groundedness         | 5.0 / 5        |
| Relevance            | 5.0 / 5        |
| Platform Compliance  | 4.47 / 5       |

---

## ğŸ“¡ Monitoring & Observability

Full distributed tracing with **OpenTelemetry** + **Azure Monitor** (Application Insights). Every workflow run, agent turn, and API call is captured as a trace.

### Components

| Module                  | File                          | Purpose                                                      |
| ----------------------- | ----------------------------- | ------------------------------------------------------------ |
| **Tracing Setup**       | `monitoring/tracing.py`       | Configures Azure Monitor exporter, enables auto-instrumentation (FastAPI, requests, httpx, azure_sdk), gracefully degrades if not configured |
| **PII Scrubber**        | `monitoring/pii_middleware.py`| OpenTelemetry `SpanProcessor` that scrubs PII from span attributes before export |
| **Agent Telemetry**     | `monitoring/agent_middleware.py` | Creates per-agent child spans with turn duration, char counts, token estimates, and reasoning pattern labels |

### PII Patterns Scrubbed

| Pattern            | Example Input                     | Redacted As          |
| ------------------ | --------------------------------- | -------------------- |
| Email addresses    | `user@example.com`                | `[EMAIL_REDACTED]`   |
| Phone numbers      | `+1-555-123-4567`                 | `[PHONE_REDACTED]`   |
| Credit card numbers| `4111-1111-1111-1111`             | `[CC_REDACTED]`      |
| IPv4 addresses     | `192.168.1.1`                     | `[IP_REDACTED]`      |
| Bearer/API tokens  | `Bearer sk-abc123...`             | `Bearer [TOKEN_REDACTED]` |

### Per-Agent Span Attributes

Each agent turn creates a child span under the workflow root span with:

- `agent.name` â€” Creator, Reviewer, Publisher, or Orchestrator
- `agent.reasoning_pattern` â€” Chain-of-Thought, ReAct, Self-Reflection, or GroupChat
- `agent.turn_index` â€” Sequential turn number (1, 2, 3, â€¦)
- `agent.output_chars` â€” Character count of the agent's response
- `agent.estimated_output_tokens` â€” Approximate token estimate (chars Ã· 4)
- `agent.turn_duration_ms` â€” Wall-clock time for the turn in milliseconds

### Setup

1. **Create an Application Insights resource** in Azure Portal
2. **Copy the connection string** and add it to `.env`:

```env
APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=<key>;IngestionEndpoint=https://<region>.in.applicationinsights.azure.com/;...
```

3. **Install dependencies** (already in `requirements.txt`):

```powershell
pip install azure-monitor-opentelemetry opentelemetry-api opentelemetry-sdk
```

4. **Run the workflow** â€” tracing activates automatically:

```powershell
$env:PYTHONIOENCODING="utf-8"
.\venv\Scripts\python.exe workflow_social_media.py
# Output: ğŸ›¡ï¸ PII scrubbing middleware attached to trace pipeline
#         âœ… Observability enabled â€” traces â†’ Application Insights
```

5. **View traces** in Azure Portal â†’ Application Insights â†’ Transaction Search â†’ End-to-end tracing

### Graceful Degradation

If `APPLICATIONINSIGHTS_CONNECTION_STRING` is not set or `azure-monitor-opentelemetry` is not installed, the workflow runs normally without tracing â€” no errors, no side effects.

---
## ğŸ›¡ï¸ Content Safety

Two-layer content safety shield that screens both **input** (campaign briefs) and **output** (agent-generated content) before it reaches the user.

### Architecture

```
User Brief â”€â”€â–º [INPUT SHIELD] â”€â”€â–º Agents â”€â”€â–º [OUTPUT SHIELD] â”€â”€â–º Response
                 â”‚                              â”‚
                 â”œâ”€ Azure Content Safety         â”œâ”€ Azure Content Safety
                 â”‚   (Hate/Violence/Sexual/      â”‚   (Hate/Violence/Sexual/
                 â”‚    Self-Harm)                  â”‚    Self-Harm)
                 â””â”€ Jailbreak Detection          â”œâ”€ Competitor Mentions
                                                 â”œâ”€ Banned Word Filter
                                                 â”œâ”€ Unsafe Activity Filter
                                                 â””â”€ PII Detection
```

### Layer 1 â€” Azure AI Content Safety (Cloud)

Uses the `azure-ai-contentsafety` SDK to screen text against 4 harm categories:

| Category  | Blocks At       | Warns At       |
| --------- | --------------- | -------------- |
| Hate      | Severity â‰¥ 4/6  | Severity â‰¥ 2/6 |
| Violence  | Severity â‰¥ 4/6  | Severity â‰¥ 2/6 |
| Sexual    | Severity â‰¥ 4/6  | Severity â‰¥ 2/6 |
| Self-Harm | Severity â‰¥ 4/6  | Severity â‰¥ 2/6 |

Gracefully degrades if `CONTENT_SAFETY_ENDPOINT` is not configured â€” brand filters still run.

### Layer 2 â€” Brand-Specific Filters (Local)

Pure-Python regex filters â€” no cloud dependency, always active:

| Filter              | Severity  | What It Catches                                                 |
| ------------------- | --------- | --------------------------------------------------------------- |
| Competitor mentions  | ğŸ”´ Block | VoyageNow, CookTravel, WanderPath                              |
| Banned words         | ğŸŸ¡ Warn  | "cheap", "tourist", "package deal", "discount", "basic" (with suggestions) |
| Unsafe activities    | ğŸ”´ Block | Dangerous without safety gear, binge drinking, cultural insensitivity |
| PII in content       | ğŸ”´ Block | Email addresses, phone numbers, SSN-like patterns               |
| Jailbreak detection  | ğŸ”´ Block | "Ignore previous instructions", DAN mode, system prompt injection |

### Setup

1. **(Optional)** Create an Azure AI Content Safety resource and add to `.env`:

```env
CONTENT_SAFETY_ENDPOINT=https://<resource>.cognitiveservices.azure.com
# CONTENT_SAFETY_KEY=<key>  # Or use DefaultAzureCredential (recommended)
```

2. Brand filters work out of the box â€” no configuration needed.

### Integration Points

- **CLI workflow** (`workflow_social_media.py`): Screens campaign brief before agents run + screens publisher output before saving
- **API server** (`api_server.py`): `POST /api/generate` screens input (returns `400` if blocked) + screens output (adds `safety` field to response)

### API Response â€” Safety Field

```json
{
  "status": "success",
  "posts": { ... },
  "safety": {
    "status": "passed",
    "flags": []
  }
}
```

Possible `safety.status` values: `"passed"`, `"warnings"`, `"blocked"`.

### Test Results

Validated against all 16 project safety test cases â€” **25/25 filter tests passed**.

---
## ï¿½ğŸ”’ Security

- âœ… `DefaultAzureCredential` â€” no hardcoded API keys
- âœ… `.env` excluded via `.gitignore`
- âœ… `.env.sample` with placeholders only
- âœ… No PII, customer data, or confidential content
- âœ… All Azure resource names parameterized

---

## ğŸ¯ Hackathon Milestones

| #   | Milestone                                            | Status |
| --- | ---------------------------------------------------- | ------ |
| 1   | Environment setup (Foundry + model deployment)       | âœ…     |
| 2   | Agent creation (Creator, Reviewer, Publisher)        | âœ…     |
| 3   | Grounding knowledge (File Search + brand guidelines) | âœ…     |
| 4   | External tools (MCP filesystem integration)          | âœ…     |

### Bonus Features (Optional)

| Feature            | Package                       | Status   |
| ------------------ | ----------------------------- | -------- |
| Observability      | `azure-monitor-opentelemetry` | âœ… Done  |
| Content Safety     | `azure-ai-contentsafety`      | âœ… Done  |
| Agentic Evaluation | `azure-ai-evaluation`         | âœ… Done  |

---

## ï¿½ ## MCP Filesystem Integration

The Publisher agent saves posts to `./output/` via the [Model Context Protocol](https://modelcontextprotocol.io) using `@modelcontextprotocol/server-filesystem`.

### Transport Modes

Set `MCP_TRANSPORT` in `.env` to choose (default: `stdio`):

| Mode                | Env Value         | How It Works                                                                                                        |
| ------------------- | ----------------- | ------------------------------------------------------------------------------------------------------------------- |
| **Stdio** (default) | `stdio`           | Direct stdio pipe to the MCP server. Simplest setup.                                                                |
| **HTTP Streamable** | `streamable-http` | Uses [supergateway](https://github.com/nichochar/supergateway) as a bridge. Requires `npm install -g supergateway`. |

```
# Stdio (default)
Publisher Agent -> MCPStdioTool -> npx server-filesystem ./output

# HTTP Streamable (opt-in)
Publisher Agent -> MCPStreamableHTTPTool -> http://127.0.0.1:8000/mcp
                                              | supergateway
                                              v
                                       npx server-filesystem ./output
```

| Setting          | Default    | Override                                      |
| ---------------- | ---------- | --------------------------------------------- |
| Transport        | `stdio`    | `MCP_TRANSPORT` env var                       |
| Port (HTTP only) | `8000`     | `MCP_SERVER_PORT` env var                     |
| Output dir       | `./output` | Pass `output_dir` to `get_filesystem_tools()` |

---

## Resources

- [Microsoft Foundry Documentation](https://learn.microsoft.com/azure/ai-foundry/)
- [Microsoft Agent Framework](https://github.com/microsoft/agent-framework)
- [GitHub Copilot SDK](https://github.com/github/copilot-sdk)
- [Starter Code Repository](https://github.com/sureshpaulraj/aiagent-maf-githubcopilotsdk)

---

âš ï¸ **Security Notice**: This is a PUBLIC repository. See [DISCLAIMER.md](DISCLAIMER.md) for guidelines. See also the [original hackathon README](README_OLD.md) for competition rules.

**Good luck! Wander More, Spend Less ğŸŒâœˆï¸**
